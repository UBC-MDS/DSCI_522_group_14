{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68e3ec5e-7b9d-4e63-ac2e-7f157736fe25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import string\n",
    "import pickle\n",
    "\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import make_scorer, f1_score, SCORERS\n",
    "from sklearn.model_selection import (\n",
    "    RandomizedSearchCV,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import (\n",
    "    OneHotEncoder,\n",
    "    OrdinalEncoder,\n",
    ")\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0988a32d-ca71-4062-8df1-67387484bbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read X_train\n",
    "read_path = \"../data/processed/heritage_train.csv\"\n",
    "train_data = pd.read_csv(read_path)\n",
    "\n",
    "# Separate X and y\n",
    "X_train = train_data.drop(\n",
    "    columns=[\"amount_category\", \"amount_approved\", \"audiences_none\"]\n",
    ")\n",
    "y_train = train_data[\"amount_category\"]\n",
    "\n",
    "# Selecting Feature Categories\n",
    "\n",
    "drop_feature = [\n",
    "    \"fiscal_year\",\n",
    "    \"region\",\n",
    "    \"disciplines_other\",\n",
    "    \"organization_name\",\n",
    "]  # droping region as provice is already an indicator of region\n",
    "\n",
    "text_countvec = \"project_name\"\n",
    "categorical_ohe = [\"city\", \"province\", \"project_type\"]\n",
    "ordinal = [\"community_type\"]\n",
    "Community_order = [[\"Remote\", \"Rural\", \"Small Urban\", \"Medium Urban\", \"Large Urban\"]]\n",
    "\n",
    "binary = list(\n",
    "    set(X_train.columns.tolist())\n",
    "    - set(drop_feature)\n",
    "    - set([text_countvec])\n",
    "    - set(categorical_ohe)\n",
    "    - set(ordinal)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7ac5d38-6d60-4af4-ae84-ca2be7cf2b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Column Transformers\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (CountVectorizer(max_features=400, stop_words=\"english\"), text_countvec),\n",
    "    (\n",
    "        OneHotEncoder(\n",
    "            handle_unknown=\"ignore\",\n",
    "        ),\n",
    "        categorical_ohe,\n",
    "    ),\n",
    "    (OneHotEncoder(drop=\"if_binary\", handle_unknown=\"ignore\"), binary),\n",
    "    (\n",
    "        OrdinalEncoder(\n",
    "            categories=Community_order,\n",
    "        ),\n",
    "        ordinal,\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a74ce5a5-a8c5-45ad-92bf-568c86e00d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artan\\miniconda3\\envs\\Cdn_heritage_funding\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\artan\\miniconda3\\envs\\Cdn_heritage_funding\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:170: UserWarning: Found unknown categories in columns [3, 11] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "C:\\Users\\artan\\miniconda3\\envs\\Cdn_heritage_funding\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\artan\\miniconda3\\envs\\Cdn_heritage_funding\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\artan\\miniconda3\\envs\\Cdn_heritage_funding\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\artan\\miniconda3\\envs\\Cdn_heritage_funding\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\artan\\miniconda3\\envs\\Cdn_heritage_funding\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:170: UserWarning: Found unknown categories in columns [3, 11] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "C:\\Users\\artan\\miniconda3\\envs\\Cdn_heritage_funding\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:170: UserWarning: Found unknown categories in columns [3, 11] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "C:\\Users\\artan\\miniconda3\\envs\\Cdn_heritage_funding\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:170: UserWarning: Found unknown categories in columns [3, 11] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "C:\\Users\\artan\\miniconda3\\envs\\Cdn_heritage_funding\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:170: UserWarning: Found unknown categories in columns [3, 11] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Scoring methods to be used for multilabel classification\n",
    "\n",
    "scoring = ['f1_weighted', 'recall_weighted', 'precision_weighted']\n",
    "\n",
    "\n",
    "# Main function\n",
    "\n",
    "models = {\n",
    "    \"Dummy Classifier\": DummyClassifier(),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, class_weight=\"balanced\"),\n",
    "    \"Multinomial Naive Bayes\": MultinomialNB(),\n",
    "    \"SVC\": SVC(class_weight=\"balanced\"),\n",
    "    \"Random Forest\": RandomForestClassifier(class_weight=\"balanced\")\n",
    "}\n",
    "\n",
    "results = pd.DataFrame()\n",
    "for name, classifier in models.items():\n",
    "    pipe = make_pipeline(preprocessor, classifier)\n",
    "    result = pd.DataFrame(cross_validate(pipe, X_train, y_train, cv=5, scoring=scoring)).mean()\n",
    "    results = pd.concat([results, pd.DataFrame(result, columns=[name])], axis=1)\n",
    "    \n",
    "\n",
    "file_path = \"../results/model_comparison.csv\"    \n",
    "try:\n",
    "    results.to_csv(file_path, encoding='utf-8')\n",
    "except:\n",
    "    os.makedirs(os.path.dirname(file_path))\n",
    "    open(file_path, \"wb\").write(results.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "815af397-3a76-4ac0-b9e1-ab95971e756b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('columntransformer',\n",
       "                                              ColumnTransformer(transformers=[('countvectorizer',\n",
       "                                                                               CountVectorizer(max_features=400,\n",
       "                                                                                               stop_words='english'),\n",
       "                                                                               'project_name'),\n",
       "                                                                              ('onehotencoder-1',\n",
       "                                                                               OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                                               ['city',\n",
       "                                                                                'province',\n",
       "                                                                                'project_type']),\n",
       "                                                                              ('onehotencoder-2',\n",
       "                                                                               OneHotEncoder(drop='if_binary',\n",
       "                                                                                             handle_unknow...\n",
       "                   param_distributions={'columntransformer__countvectorizer__max_features': [400,\n",
       "                                                                                             500,\n",
       "                                                                                             600,\n",
       "                                                                                             700,\n",
       "                                                                                             800],\n",
       "                                        'randomforestclassifier__class_weight': ['balanced',\n",
       "                                                                                 None],\n",
       "                                        'randomforestclassifier__max_depth': [None,\n",
       "                                                                              10,\n",
       "                                                                              20,\n",
       "                                                                              30,\n",
       "                                                                              40,\n",
       "                                                                              50,\n",
       "                                                                              60],\n",
       "                                        'randomforestclassifier__max_features': ['auto',\n",
       "                                                                                 'log2']},\n",
       "                   refit='f1_weighted',\n",
       "                   scoring=['f1_weighted', 'recall_weighted',\n",
       "                            'precision_weighted'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_distributions = {\n",
    "   \"columntransformer__countvectorizer__max_features\": [400, 500, 600, 700, 800],\n",
    "    \"randomforestclassifier__max_depth\": [None, 10, 20, 30, 40, 50, 60],\n",
    "    \"randomforestclassifier__max_features\": [\"auto\", \"log2\"],\n",
    "    \"randomforestclassifier__class_weight\": [\"balanced\", None]\n",
    "}\n",
    "\n",
    "\n",
    "best_model = RandomizedSearchCV(\n",
    "    make_pipeline(preprocessor, RandomForestClassifier()),\n",
    "    param_distributions=param_distributions,\n",
    "    n_jobs=-1,\n",
    "    scoring=scoring,\n",
    "    n_iter=20,\n",
    "    cv=5,\n",
    "    refit=\"f1_weighted\"\n",
    ")\n",
    "\n",
    "best_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b988406e-918e-4a95-a4cb-83d164950ac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64843013063191"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa3d9620-61b5-4786-8a0e-83ac90bafec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'randomforestclassifier__max_features': 'log2',\n",
       " 'randomforestclassifier__max_depth': None,\n",
       " 'randomforestclassifier__class_weight': 'balanced',\n",
       " 'columntransformer__countvectorizer__max_features': 500}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e07b82fe-4ce2-4cf2-9ac0-f425759039da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(best_model, open(\"../results/final_rf_model.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "726ce0a0-8ad8-446c-bcfe-91b9baafb073",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ffb82d-e198-4304-b3b4-853f59f5663a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Cdn_heritage_funding]",
   "language": "python",
   "name": "conda-env-Cdn_heritage_funding-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
